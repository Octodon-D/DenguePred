{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d05efb17",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1079a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading packages and their components\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from own_functions import train_test_timesplit\n",
    "\n",
    "# Setting Pandas options\n",
    "# pd.options.display.max_rows = 999 # For debugging, can be removed later\n",
    "pd.options.mode.chained_assignment = None  # Disabling the pandas chained assignment warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e027ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_and_preproc():\n",
    "    # Read in the data\n",
    "    dengue_features_train = pd.read_csv('data/dengue_features_train.csv')\n",
    "    dengue_features_test = pd.read_csv('data/dengue_features_test.csv')\n",
    "    dengue_labels_train = pd.read_csv('data/dengue_labels_train.csv')\n",
    "\n",
    "    raw_data = [dengue_features_train, dengue_features_test, dengue_labels_train]\n",
    "    \n",
    "    # Splitting the data into a San Juan and an Iquitos part\n",
    "    iq = []\n",
    "    sj = []\n",
    "    for item in raw_data:\n",
    "        sj.append( item[item.city=='sj'] )\n",
    "        iq.append( item[item.city=='iq'] )\n",
    "\n",
    "    # Transferring the date column to the label part of the data\n",
    "    sj[2] = sj[2].join(sj[0]['week_start_date'])\n",
    "    iq[2] = iq[2].join(iq[0]['week_start_date'])\n",
    "\n",
    "    # Converting the date column to datetime format\n",
    "    for i in range(len(sj)):\n",
    "        sj[i]['week_start_date'] = pd.to_datetime(sj[i]['week_start_date'], format='%Y-%m-%d')  \n",
    "        iq[i]['week_start_date'] = pd.to_datetime(iq[i]['week_start_date'], format='%Y-%m-%d')\n",
    "        \n",
    "    # Putting the date as index\n",
    "    for i in range(len(sj)):\n",
    "        sj[i] = sj[i].set_index('week_start_date', drop=False)\n",
    "        iq[i] = iq[i].set_index('week_start_date', drop=False)\n",
    "        \n",
    "    return list([sj[0], sj[1], sj[2], iq[0], iq[1], iq[2]])\n",
    "\n",
    "data_subsets = import_and_preproc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d488c1",
   "metadata": {},
   "source": [
    "## Features in the dataset\n",
    "City and date indicators\n",
    "* `city` – City abbreviations: `sj` for San Juan and `iq` for Iquitos\n",
    "* `week_start_date` – Date given in yyyy-mm-dd format\n",
    "\n",
    "NOAA's GHCN daily climate data weather station measurements\n",
    "* `station_max_temp_c` – Maximum temperature\n",
    "* `station_min_temp_c` – Minimum temperature\n",
    "* `station_avg_temp_c` – Average temperature\n",
    "* `station_precip_mm` – Total precipitation\n",
    "* `station_diur_temp_rng_c` – Diurnal temperature range\n",
    "\n",
    "PERSIANN satellite precipitation measurements (0.25x0.25 degree scale)\n",
    "* `precipitation_amt_mm` – Total precipitation\n",
    "\n",
    "NOAA's NCEP Climate Forecast System Reanalysis measurements (0.5x0.5 degree scale)\n",
    "* `reanalysis_air_temp_k` – Mean air temperature\n",
    "* `reanalysis_relative_humidity_percen` – Mean relative humidity\n",
    "* `reanalysis_specific_humidity_g_per_kg` – Mean specific humidity\n",
    "* `reanalysis_precip_amt_kg_per_mm` – Total precipitation\n",
    "* `reanalysis_max_air_temp_k` – Maximum air temperature\n",
    "* `reanalysis_min_air_temp_k` – Minimum air temperature\n",
    "* `reanalysis_avg_temp_k` – Average air temperature\n",
    "* `reanalysis_tdtr_k` – Diurnal temperature range\n",
    "\n",
    "Satellite vegetation - Normalized difference vegetation index (NDVI) - NOAA's CDR Normalized Difference Vegetation Index (0.5x0.5 degree scale) measurements\n",
    "* `ndvi_se` – Pixel southeast of city centroid\n",
    "* `ndvi_sw` – Pixel southwest of city centroid\n",
    "* `ndvi_ne` – Pixel northeast of city centroid\n",
    "* `ndvi_nw` – Pixel northwest of city centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3594a70",
   "metadata": {},
   "source": [
    "## Missing value imputation\n",
    "Since the environmental values for each week are assumed to follow seasonal patterns, they can not be simply replaced with the mean over the entire study. Intstead, missing values in these variables can be replaced with the mean value of the week before and after, or the week before and after that has no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95989954",
   "metadata": {},
   "outputs": [],
   "source": [
    "environmental_vars = [\n",
    "    'ndvi_ne',\n",
    "    'ndvi_nw',\n",
    "    'ndvi_se', \n",
    "    'ndvi_sw',\n",
    "    'precipitation_amt_mm',\n",
    "    'reanalysis_air_temp_k',\n",
    "    'reanalysis_avg_temp_k',\n",
    "    'reanalysis_dew_point_temp_k',\n",
    "    'reanalysis_max_air_temp_k',\n",
    "    'reanalysis_min_air_temp_k',\n",
    "    'reanalysis_precip_amt_kg_per_m2',\n",
    "    'reanalysis_relative_humidity_percent',\n",
    "    'reanalysis_sat_precip_amt_mm',\n",
    "    'reanalysis_specific_humidity_g_per_kg',\n",
    "    'reanalysis_tdtr_k',\n",
    "    'station_avg_temp_c',\n",
    "    'station_diur_temp_rng_c',\n",
    "    'station_max_temp_c',\n",
    "    'station_min_temp_c',\n",
    "    'station_precip_mm'\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c476ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing(df, colnames):\n",
    "    # Store the time index because the code below is index based and needs numbers\n",
    "    date = df.index\n",
    "    df = df.reset_index(drop=True)\n",
    "    for colname in colnames:\n",
    "        try: # because there are columns that do not occur in all subsets of the dataset\n",
    "            miss_idx = df[df[colname].isnull()].index.tolist()\n",
    "            for idx in miss_idx:\n",
    "                    # Search the nearest week before the week with the missing value\n",
    "                    # that itself has no missing value\n",
    "                    before = df.iloc[:idx,:][colname].dropna().tail(1)\n",
    "                    # The same but for the weeks after the missing value\n",
    "                    after = df.iloc[idx:,:][colname].dropna().head(1)\n",
    "                    # Replace the missing value with the mean\n",
    "                    df[colname][idx] = np.mean([before, after])\n",
    "        except:\n",
    "            continue\n",
    "    # Re-attach the time index and drop the auxiliary index\n",
    "    df = df.set_index(date, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc2b752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the Imputation\n",
    "for i in range(len(data_subsets)):\n",
    "    data_subsets[i] = replace_missing(data_subsets[i], environmental_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b574bb",
   "metadata": {},
   "source": [
    "Check if there are still variables with missing values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0932b28b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city                                     0\n",
      "year                                     0\n",
      "weekofyear                               0\n",
      "week_start_date                          0\n",
      "ndvi_ne                                  0\n",
      "ndvi_nw                                  0\n",
      "ndvi_se                                  0\n",
      "ndvi_sw                                  0\n",
      "precipitation_amt_mm                     0\n",
      "reanalysis_air_temp_k                    0\n",
      "reanalysis_avg_temp_k                    0\n",
      "reanalysis_dew_point_temp_k              0\n",
      "reanalysis_max_air_temp_k                0\n",
      "reanalysis_min_air_temp_k                0\n",
      "reanalysis_precip_amt_kg_per_m2          0\n",
      "reanalysis_relative_humidity_percent     0\n",
      "reanalysis_sat_precip_amt_mm             0\n",
      "reanalysis_specific_humidity_g_per_kg    0\n",
      "reanalysis_tdtr_k                        0\n",
      "station_avg_temp_c                       0\n",
      "station_diur_temp_rng_c                  0\n",
      "station_max_temp_c                       0\n",
      "station_min_temp_c                       0\n",
      "station_precip_mm                        0\n",
      "dtype: int64\n",
      "------------------------------\n",
      "city                                     0\n",
      "year                                     0\n",
      "weekofyear                               0\n",
      "week_start_date                          0\n",
      "ndvi_ne                                  0\n",
      "ndvi_nw                                  0\n",
      "ndvi_se                                  0\n",
      "ndvi_sw                                  0\n",
      "precipitation_amt_mm                     0\n",
      "reanalysis_air_temp_k                    0\n",
      "reanalysis_avg_temp_k                    0\n",
      "reanalysis_dew_point_temp_k              0\n",
      "reanalysis_max_air_temp_k                0\n",
      "reanalysis_min_air_temp_k                0\n",
      "reanalysis_precip_amt_kg_per_m2          0\n",
      "reanalysis_relative_humidity_percent     0\n",
      "reanalysis_sat_precip_amt_mm             0\n",
      "reanalysis_specific_humidity_g_per_kg    0\n",
      "reanalysis_tdtr_k                        0\n",
      "station_avg_temp_c                       0\n",
      "station_diur_temp_rng_c                  0\n",
      "station_max_temp_c                       0\n",
      "station_min_temp_c                       0\n",
      "station_precip_mm                        0\n",
      "dtype: int64\n",
      "------------------------------\n",
      "city               0\n",
      "year               0\n",
      "weekofyear         0\n",
      "total_cases        0\n",
      "week_start_date    0\n",
      "dtype: int64\n",
      "------------------------------\n",
      "city                                     0\n",
      "year                                     0\n",
      "weekofyear                               0\n",
      "week_start_date                          0\n",
      "ndvi_ne                                  0\n",
      "ndvi_nw                                  0\n",
      "ndvi_se                                  0\n",
      "ndvi_sw                                  0\n",
      "precipitation_amt_mm                     0\n",
      "reanalysis_air_temp_k                    0\n",
      "reanalysis_avg_temp_k                    0\n",
      "reanalysis_dew_point_temp_k              0\n",
      "reanalysis_max_air_temp_k                0\n",
      "reanalysis_min_air_temp_k                0\n",
      "reanalysis_precip_amt_kg_per_m2          0\n",
      "reanalysis_relative_humidity_percent     0\n",
      "reanalysis_sat_precip_amt_mm             0\n",
      "reanalysis_specific_humidity_g_per_kg    0\n",
      "reanalysis_tdtr_k                        0\n",
      "station_avg_temp_c                       0\n",
      "station_diur_temp_rng_c                  0\n",
      "station_max_temp_c                       0\n",
      "station_min_temp_c                       0\n",
      "station_precip_mm                        0\n",
      "dtype: int64\n",
      "------------------------------\n",
      "city                                     0\n",
      "year                                     0\n",
      "weekofyear                               0\n",
      "week_start_date                          0\n",
      "ndvi_ne                                  0\n",
      "ndvi_nw                                  0\n",
      "ndvi_se                                  0\n",
      "ndvi_sw                                  0\n",
      "precipitation_amt_mm                     0\n",
      "reanalysis_air_temp_k                    0\n",
      "reanalysis_avg_temp_k                    0\n",
      "reanalysis_dew_point_temp_k              0\n",
      "reanalysis_max_air_temp_k                0\n",
      "reanalysis_min_air_temp_k                0\n",
      "reanalysis_precip_amt_kg_per_m2          0\n",
      "reanalysis_relative_humidity_percent     0\n",
      "reanalysis_sat_precip_amt_mm             0\n",
      "reanalysis_specific_humidity_g_per_kg    0\n",
      "reanalysis_tdtr_k                        0\n",
      "station_avg_temp_c                       0\n",
      "station_diur_temp_rng_c                  0\n",
      "station_max_temp_c                       0\n",
      "station_min_temp_c                       0\n",
      "station_precip_mm                        0\n",
      "dtype: int64\n",
      "------------------------------\n",
      "city               0\n",
      "year               0\n",
      "weekofyear         0\n",
      "total_cases        0\n",
      "week_start_date    0\n",
      "dtype: int64\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check if there are still variables with missing values in our dataset.\n",
    "for subset in data_subsets:\n",
    "    print(subset.isnull().sum())\n",
    "    print('---'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911422cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature editing\n",
    "The temperature features from the NCEP Climate Forecast System Reanalysis and those of the weather station are in different units. To have the temperature features in the same units as those of the NCEP Climate Forecast System, the Reanalysis variables will be converted to degrees Celsius. For uniformity, the diurnal temperature range is converted from Celsius to Kelvin, as differences in temperature are expressed in Kelvin. Furthermore, the feature `precipitation_amt_mm` is removed as its values are identical to those of `reanalysis_precip_amt_kg_per_mm`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b1c373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 reanalysis_sat_precip_amt_mm  precipitation_amt_mm\n",
      "week_start_date                                                    \n",
      "1995-02-12                               0.00                  0.00\n",
      "2004-06-17                              13.07                 13.07\n",
      "2000-05-27                              39.45                 39.45\n",
      "2003-12-10                             182.81                182.81\n",
      "2006-09-17                              67.31                 67.31\n",
      "                 reanalysis_sat_precip_amt_mm  precipitation_amt_mm\n",
      "week_start_date                                                    \n",
      "2010-03-19                               0.00                  0.00\n",
      "2009-12-17                               1.88                  1.88\n",
      "2011-06-11                              71.88                 71.88\n",
      "2008-10-28                               0.00                  0.00\n",
      "2013-02-26                               0.00                  0.00\n",
      "                 reanalysis_sat_precip_amt_mm  precipitation_amt_mm\n",
      "week_start_date                                                    \n",
      "2008-07-15                              62.84                 62.84\n",
      "2004-03-25                             120.10                120.10\n",
      "2008-02-05                              38.72                 38.72\n",
      "2008-04-29                              42.12                 42.12\n",
      "2006-10-29                              55.94                 55.94\n",
      "                 reanalysis_sat_precip_amt_mm  precipitation_amt_mm\n",
      "week_start_date                                                    \n",
      "2013-04-30                               2.28                  2.28\n",
      "2013-05-21                              87.29                 87.29\n",
      "2012-09-09                               6.40                  6.40\n",
      "2012-09-02                              34.14                 34.14\n",
      "2011-07-23                              70.29                 70.29\n"
     ]
    }
   ],
   "source": [
    "# compare 'reanalysis_sat_precip_amt_mm' and 'precipitation_amt_mm'\n",
    "for i in range(len(data_subsets)):\n",
    "    if data_subsets[i].shape[1] > 5:\n",
    "        print(data_subsets[i][['reanalysis_sat_precip_amt_mm', 'precipitation_amt_mm']].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd35f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply unit conversion, renaming and dropping \n",
    "for i in range(len(data_subsets)):\n",
    "    if data_subsets[i].shape[1] > 5:\n",
    "        data_subsets[i] = (\n",
    "            data_subsets[i]\n",
    "            .assign(month = lambda df: df.index.month)\n",
    "            .assign(reanalysis_air_temp_c = lambda df: df['reanalysis_air_temp_k']-273.15)\n",
    "            .assign(reanalysis_avg_temp_c = lambda df: df['reanalysis_avg_temp_k']-273.15)\n",
    "            .assign(reanalysis_dew_point_temp_c = lambda df: df['reanalysis_dew_point_temp_k']-273.15)\n",
    "            .assign(reanalysis_max_air_temp_c = lambda df: df['reanalysis_max_air_temp_k']-273.15)\n",
    "            .assign(reanalysis_min_air_temp_c = lambda df: df['reanalysis_min_air_temp_k']-273.15)\n",
    "            .rename(columns={'station_diur_temp_rng_c': 'station_diur_temp_rng_k'})\n",
    "            .drop(['reanalysis_air_temp_k','reanalysis_avg_temp_k', 'reanalysis_dew_point_temp_k', 'reanalysis_max_air_temp_k',\n",
    "                   'reanalysis_min_air_temp_k','precipitation_amt_mm'], axis=1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e57540f",
   "metadata": {},
   "source": [
    "## Adding the population data\n",
    "\n",
    "This additional data is available from the Dengue Forecasting [website](https://dengueforecasting.noaa.gov/), from which the data provided by DrivenData originates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17c8d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pop(filename):\n",
    "    ser = (\n",
    "        pd.read_csv(filename)\n",
    "        .assign(year = lambda df: df.Year) # to have a same-name column with the other dataframes\n",
    "        .assign(Year = lambda df: pd.to_datetime(df.Year, format='%Y'))\n",
    "        .set_index('Year', drop=True)\n",
    "    )\n",
    "    return ser\n",
    "sj_pop = load_pop('data/San_Juan_Population_Data.csv')\n",
    "iq_pop = load_pop('data/Iquitos_Population_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a181c6b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_pop(df, pop):\n",
    "    merged = pd.merge(df, pop, how='left', on='year')\n",
    "    merged = merged.rename(columns={'Estimated_population': 'population'})\n",
    "    merged = merged.set_index('week_start_date', drop=True)\n",
    "    merged.population = merged.population.interpolate().round().astype(int)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae5c36d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subsets[0] = merge_pop(data_subsets[0], sj_pop)\n",
    "data_subsets[1] = merge_pop(data_subsets[1], sj_pop)\n",
    "data_subsets[2] = data_subsets[2].set_index('week_start_date', drop=True)\n",
    "data_subsets[3] = merge_pop(data_subsets[3], iq_pop)\n",
    "data_subsets[4] = merge_pop(data_subsets[4], iq_pop)\n",
    "data_subsets[5] = data_subsets[5].set_index('week_start_date', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27d584db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into their parts\n",
    "sj_features_train, \\\n",
    "sj_features_test, \\\n",
    "sj_labels_train, \\\n",
    "iq_features_train, \\\n",
    "iq_features_test, \\\n",
    "iq_labels_train = data_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b25ed708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(data_subsets, open('cleaned_data.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa84887",
   "metadata": {},
   "source": [
    "## Train test split\n",
    "To evaluate forecasting models, a train and a seperate test dataset (with actual values for the number of cases) is needed. Therefore the given \"train\" datasets for both cities is split into a `train_train` (75% of the data) and a `train_test` (25% of the data) set. \n",
    "\n",
    "### Exclude data before 2002 from Iquitos\n",
    "The total number of cases form Iquitos only contain single values. After 01.01.2002 the total number of cases increases clearly, probably due to a difference in the reposting system or counting system. Consequently the values before 2002 will be excluded from the dataset used for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bede5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove entries in IQ data until 2002 (data excluded from modeling)\n",
    "data_subsets[3] = data_subsets[3]['2002':]\n",
    "data_subsets[5] = data_subsets[5]['2002':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "158f257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split given data (features and label) into test and train datasets\n",
    "def split_dataset(data_subsets):\n",
    "    data_subsets_splitted = []\n",
    "    for i in [0, 2, 3, 5]:\n",
    "        train, test = train_test_timesplit(data_subsets[i])\n",
    "        data_subsets_splitted.append(train)\n",
    "        data_subsets_splitted.append(test)\n",
    "    return data_subsets_splitted\n",
    "\n",
    "data_subsets_splitted = split_dataset(data_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5811d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the splitted data subsets in a pickle\n",
    "# pickle.dump(data_subsets_splitted, open('splitted_data.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd582b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into their parts\n",
    "sj_features_train_train, \\\n",
    "sj_features_train_test, \\\n",
    "sj_labels_train_train, \\\n",
    "sj_labels_train_test, \\\n",
    "iq_features_train_train, \\\n",
    "iq_features_train_test, \\\n",
    "iq_labels_train_train, \\\n",
    "iq_labels_train_test = data_subsets_splitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a30fca2",
   "metadata": {},
   "source": [
    "Combine data for one `train_train` and `train_test` set for each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bc4e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join feature and label dataset\n",
    "sj_train_train = sj_features_train_train.join(sj_labels_train_train['total_cases'])\n",
    "sj_train_test = sj_features_train_test.join(sj_labels_train_test['total_cases'])\n",
    "iq_train_train = iq_features_train_train.join(iq_labels_train_train['total_cases'])\n",
    "iq_train_test = iq_features_train_test.join(iq_labels_train_test['total_cases'])\n",
    "\n",
    "# combine all four datasets\n",
    "data_subsets_splitted_joined = [sj_train_train, sj_train_test, iq_train_train, iq_train_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a990bbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the splitted data subsets in a pickle\n",
    "pickle.dump(data_subsets_splitted_joined, open('splitted_joined_data.pickle', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
